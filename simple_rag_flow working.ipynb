{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04f45e89",
   "metadata": {},
   "source": [
    "# Simple RAG LLM Flow\n",
    "A  implementation of RAG search followed by LLM summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67617cc9",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e294e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c3b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poorvikjaintm/learn_llm/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List, Dict, Any, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "import json\n",
    "import psycopg2\n",
    "import ollama\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d45f4c",
   "metadata": {},
   "source": [
    "## State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76658ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    \"\"\"Simple state class for RAG to LLM flow with proper message handling.\"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    query: Optional[str] = None\n",
    "    next_node: Optional[str] = None\n",
    "    search_results: Optional[Dict[str, Any]] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563e14b",
   "metadata": {},
   "source": [
    "## Node Handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c11616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DB_CONN = \"dbname=ragdb user=postgres password=postgres host=localhost\"\n",
    "EMBED_MODEL = \"embeddinggemma\"\n",
    "LLM_MODEL = \"phi3:mini\"\n",
    "TOP_K = 1\n",
    "\n",
    "def embed_text(text: str):\n",
    "    \"\"\"Get vector embedding from Ollama.\"\"\"\n",
    "    response = ollama.embeddings(model=EMBED_MODEL, prompt=text)\n",
    "    return response[\"embedding\"]\n",
    "\n",
    "def search_documents(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Search for relevant documents.\"\"\"\n",
    "    q_emb = embed_text(query)\n",
    "    conn = psycopg2.connect(DB_CONN)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        SELECT filename, content, job_information\n",
    "        FROM json_docs\n",
    "        ORDER BY embedding <#> %s::vector\n",
    "        LIMIT %s;\n",
    "    \"\"\", (q_emb, TOP_K))\n",
    "    \n",
    "    results = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return [{\n",
    "        \"filename\": r[0],\n",
    "        \"content\": r[1],\n",
    "        \"job_information\": json.loads(r[2]) if isinstance(r[2], str) else r[2]\n",
    "    } for r in results]\n",
    "\n",
    "\n",
    "def rag_handler(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Handle document retrieval.\"\"\"\n",
    "    try:\n",
    "        results = search_documents(state[\"query\"])\n",
    "        if results:\n",
    "            state[\"search_results\"] = results[0]\n",
    "            state[\"next_node\"] = \"llm\"\n",
    "        else:\n",
    "            state[\"messages\"].append(AIMessage(content=\"No matching documents found.\"))\n",
    "            state[\"next_node\"] = \"end\"\n",
    "    except Exception as e:\n",
    "        state[\"messages\"].append(AIMessage(content=f\"Search error: {str(e)}\"))\n",
    "        state[\"next_node\"] = \"end\"\n",
    "    return state\n",
    "\n",
    "def llm_handler(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Generate summary using LLM.\"\"\"\n",
    "    if not state.get(\"search_results\"):\n",
    "        state[\"messages\"].append(AIMessage(content=\"No search results to summarize.\"))\n",
    "        state[\"next_node\"] = \"end\"\n",
    "        return state\n",
    "    \n",
    "    job_info = state[\"search_results\"][\"job_information\"].get(\"job_information\", {})\n",
    "    \n",
    "    prompt = f\"\"\"Job Title: {job_info.get('title')}\n",
    "Company: {job_info.get('client')}\n",
    "Location: {job_info.get('location')}\n",
    "\n",
    "List only the key information from this job posting without adding explanations.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(model=LLM_MODEL, messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }])\n",
    "        summary = response[\"message\"][\"content\"]\n",
    "        state[\"messages\"].append(AIMessage(content=summary))\n",
    "    except Exception as e:\n",
    "        state[\"messages\"].append(AIMessage(content=f\"Error generating summary: {str(e)}\"))\n",
    "    \n",
    "    state[\"next_node\"] = \"end\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df417599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match explanation functionality\n",
    "\n",
    "def search_documents_with_explanation(query: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Search for relevant documents with match explanation.\"\"\"\n",
    "    q_emb = embed_text(query)\n",
    "    conn = psycopg2.connect(DB_CONN)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        SELECT filename, content, job_information, embedding <#> %s::vector as distance\n",
    "        FROM json_docs\n",
    "        ORDER BY embedding <#> %s::vector\n",
    "        LIMIT %s;\n",
    "    \"\"\", (q_emb, q_emb, TOP_K))\n",
    "    \n",
    "    query_response = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    results = [{\n",
    "        \"filename\": r[0],\n",
    "        \"content\": r[1],\n",
    "        \"job_information\": json.loads(r[2]) if isinstance(r[2], str) else r[2],\n",
    "        \"distance\": r[3]\n",
    "    } for r in query_response]\n",
    "    return results\n",
    "\n",
    "def rag_handler_with_explanation(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Handle document retrieval with match explanation.\"\"\"\n",
    "    try:\n",
    "        results = search_documents_with_explanation(state[\"query\"])\n",
    "        if results:\n",
    "            state[\"search_results\"] = results[0]\n",
    "            # Add match explanation\n",
    "            job_info = results[0][\"job_information\"].get(\"job_information\", {})\n",
    "            match_info = f\"Match found: {results[0]['filename']} (distance: {results[0]['distance']:.3f})\\n'\"\n",
    "            state[\"messages\"].append(AIMessage(content=match_info))\n",
    "            state[\"next_node\"] = \"llm\"\n",
    "        else:\n",
    "            state[\"messages\"].append(AIMessage(content=\"No matching documents found.\"))\n",
    "            state[\"next_node\"] = \"end\"\n",
    "    except Exception as e:\n",
    "        state[\"messages\"].append(AIMessage(content=f\"Search error: {str(e)}\"))\n",
    "        state[\"next_node\"] = \"end\"\n",
    "    return state\n",
    "def intend_handler(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Determine next node based on state[query].\"\"\"\n",
    "    prompt2 = f\"\"\"Based on this user query: \"{state['query']}\"\n",
    "    \n",
    "Respond with only one word: either \"rag\" or \"end\"\n",
    "- If the query is about jobs, job search, companies, or work-related topics, respond: rag\n",
    "- If the query is a greeting, casual conversation, or unrelated to jobs, respond: end\n",
    "\n",
    "Query: {state['query']}\n",
    "Response:\"\"\"\n",
    "    prompt = f\"\"\"Based on this user query: \"{state['query']}\"\n",
    "If the user is searching for a job, requesting job details, company information, or discussing anything related to job hunting, return 'rag'.\n",
    "If the user is greeting (e.g., \"hi\", \"hello\", \"hey\") or saying anything casual or unrelated to jobs, return 'end'.\n",
    "Respond only with the next node name.\n",
    "\n",
    "Example:\n",
    "User: \"Can you show me openings at Google?\"\n",
    "Output: rag\n",
    "\n",
    "User: \"Hi there!\"\n",
    "Output: end\n",
    "\n",
    "User: \"I want to find a software developer job.\"\n",
    "Output: rag\n",
    "\n",
    "User: \"Good morning!\"\n",
    "Output: end\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.chat(model=LLM_MODEL, messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }])\n",
    "        next_node = response[\"message\"][\"content\"].strip().lower()\n",
    "        print(\"Determined next_node:\", next_node)\n",
    "        \n",
    "        if next_node == \"end\":\n",
    "            state[\"messages\"].append(AIMessage(content=\"Hello! I can help you search for job information. What would you like to know?\"))\n",
    "            state[\"next_node\"] = \"end\"\n",
    "        else:\n",
    "            state[\"next_node\"] = \"rag\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in intent detection: {e}\")\n",
    "        state[\"next_node\"] = \"end\"\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87702f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c28eeb04",
   "metadata": {},
   "source": [
    "## Graph Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db67b0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x147703950>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure graph\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"rag\", rag_handler_with_explanation)\n",
    "graph.add_node(\"llm\", llm_handler)\n",
    "graph.add_node(\"intend\", intend_handler)\n",
    "\n",
    "# Set entry point\n",
    "graph.set_entry_point(\"rag\")\n",
    "\n",
    "\n",
    "##################\n",
    "#### -------> for intent detection \n",
    "#graph.set_entry_point(\"intend\")\n",
    "###################\n",
    "\n",
    "\n",
    "\n",
    "#### ore we can use the graph.node(START,end)\n",
    "\n",
    "# Add conditional edges\n",
    "def route_next(state):\n",
    "    return state.get(\"next_node\", \"end\")\n",
    "graph.add_conditional_edges(\n",
    "    \"intend\",\n",
    "    route_next,\n",
    "    {\n",
    "        \"rag\": \"rag\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "graph.add_conditional_edges(\n",
    "    \"rag\",\n",
    "    route_next,\n",
    "    {\n",
    "        \"llm\": \"llm\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    route_next,\n",
    "    {\"end\": END}\n",
    ")\n",
    "\n",
    "# Compile workflow\n",
    "workflow = graph.compile()\n",
    "\n",
    "workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f105d8a",
   "metadata": {},
   "source": [
    "## Test the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4520f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow with query: how are you\n",
      "\n",
      " Response:\n",
      "Match found: 07_DMART_Picker-Packer.json (distance: -0.217)\n",
      "'\n",
      "- Job Title: Picker Packer\n",
      "\n",
      "- Company: DMART\n",
      "\n",
      "- Location: All India\n",
      "\n",
      "- Required Experience Level: Entry level (High School graduate) or equivalent experience acceptable with additional support required\n",
      "\n",
      "- Expected Work Start Date: As soon as possible. Immediate start preferred, subject to background checks and drug testing results pending on time. Candidates who pass must be ready for immediate deployment upon offer acceptance due to high demand in packing warehouse operations.\n"
     ]
    }
   ],
   "source": [
    "def process_query(query: str):\n",
    "    \"\"\"Process a query through the workflow.\"\"\"\n",
    "    initial_state = {\n",
    "        \"query\": query,\n",
    "        \"messages\": [\n",
    "            SystemMessage(content=\"I am an AI assistant that can search and summarize job information.\"),\n",
    "            HumanMessage(content=query)\n",
    "        ],\n",
    "        \"next_node\": None,\n",
    "        \"search_results\": None\n",
    "    }\n",
    "    \n",
    "    return workflow.invoke(initial_state)\n",
    "\n",
    "\n",
    "test_query = \"how are you\"\n",
    "print(\"workflow with query:\", test_query)\n",
    "result = process_query(test_query)\n",
    "\n",
    "print(\"\\n Response:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage):\n",
    "        print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f74f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2885e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10533e20",
   "metadata": {},
   "source": [
    "# How to add Inmemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9964183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello! How can I assist you today? ðŸ˜Š' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 9, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CaetoZ1ZUx1zFXiffUfL5T3gsao1e', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='lc_run--5fa56bd1-2c26-4cb1-ae35-71b8fc62e2ee-0' usage_metadata={'input_tokens': 9, 'output_tokens': 11, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import os\n",
    "import dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),  \n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    temperature=0.7,\n",
    ")\n",
    "response = llm.invoke(\"hello there\")\n",
    "\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n",
    "\n",
    "memory= MemorySaver()\n",
    "\n",
    "# Define state schema\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List,add_messages]\n",
    "\n",
    "# Tool setup\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Node definition\n",
    "def tool_calling_llm(state: GraphState) -> GraphState:\n",
    "    return {\n",
    "        \"messages\": [llm_with_tools.invoke(state[\"messages\"])]\n",
    "    }\n",
    "\n",
    "# Graph creation\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
    "builder.add_edge(\"tools\",\"tool_calling_llm\")\n",
    "builder.add_edge(\"tools\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# # Invoke with proper message format\n",
    "# ans=graph.invoke({\"messages\": \"whats my name\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90dfb8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"thread_id\":\"1\"}}\n",
    "# Invoke with proper message format\n",
    "ans=graph.invoke({\"messages\": \"whats my name\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a8c4b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You haven't mentioned your name. Could you share it with me?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 1272, 'total_tokens': 1287, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CaeuE5mfXGSRqiSN0SxRCivkCPAM9', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--c2056490-9561-49ad-aa9c-37482c903f28-0', usage_metadata={'input_tokens': 1272, 'output_tokens': 15, 'total_tokens': 1287, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5465bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=graph.invoke({\"messages\": \"i am granth\"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80f23ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Granth! ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 1325, 'total_tokens': 1334, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-Caev8prqMTKPDRrN9MN4Jh7lYosIi', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--7030f06b-a62d-4e84-9a18-0d7f5fce2e9a-0', usage_metadata={'input_tokens': 1325, 'output_tokens': 9, 'total_tokens': 1334, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans=graph.invoke({\"messages\": \"whats my name \"},config=config)\n",
    "ans[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad84735",
   "metadata": {},
   "source": [
    "## Streaming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "046c6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "memory= MemorySaver()\n",
    "\n",
    "# Define state schema\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List,add_messages]\n",
    "\n",
    "\n",
    "# Node definition\n",
    "def superbot(state: GraphState) -> GraphState:\n",
    "    return {\n",
    "        \"messages\": [llm_with_tools.invoke(state[\"messages\"])]\n",
    "    }\n",
    "\n",
    "# Graph creation\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"superbot\", superbot)\n",
    "builder.add_edge(START, \"superbot\")\n",
    "\n",
    "builder.add_edge(\"superbot\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# # Invoke with proper message format\n",
    "# ans=graph.invoke({\"messages\": \"whats my name\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1df5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"thread_id\":\"1\"}}\n",
    "# Invoke with proper message format\n",
    "ans=graph.invoke({\"messages\": \"did you mention suresh previously \"},config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9d6721d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You\\'re absolutely correct! I didn\\'t mention **Suresh** earlier when listing general Indian names. My apologies for the inconsistency! \\n\\n\"Suresh\" is a more common name in general Indian contexts but not particularly associated with Jains from Karnataka. Thank you for pointing that out! ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 1623, 'total_tokens': 1683, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1536}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CaeyVip55JrZoYvPiX8dS5KLWdKcy', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--1540e4e4-e102-4c06-a43b-98875289f316-0', usage_metadata={'input_tokens': 1623, 'output_tokens': 60, 'total_tokens': 1683, 'input_token_details': {'audio': 0, 'cache_read': 1536}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfa90562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'superbot': {'messages': [AIMessage(content=\"That's a unique and wonderful name, Gingallal! Nice to meet you! ðŸ˜Š Do you want to know anything specific about your name or its origin?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 1695, 'total_tokens': 1728, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CaezEEIZrRUcB56iNcBeJcOkdNhbn', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--70564b4d-6978-4d15-b778-a867bffb5249-0', usage_metadata={'input_tokens': 1695, 'output_tokens': 33, 'total_tokens': 1728, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream({\"messages\":\"my name is gingallal\"},config=config,stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2becd18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'superbot': {'messages': [AIMessage(content='Unfortunately, the name \"Gingallal\" is not something I recognize as a common name from any specific region or culture in India or elsewhere. However, it sounds quite unique and could have a personal, family, or regional significance. To understand more about your name, you might reflect on the following:\\n\\n1. **Cultural or Regional Origin**: Does the name have roots in your family, region, or community? Sometimes unique names emerge from dialects or local traditions.\\n\\n2. **Meaning**: Many Indian names have meanings derived from Sanskrit, Kannada, or other languages. Do you know if your name has any specific meaning, or could it be a creative or modern name?\\n\\n3. **Personal Significance**: Was your name chosen for a particular reason, such as honoring someone or conveying a special sentiment?\\n\\nIf you\\'d like, I can try to help explore its possible etymology or any similar-sounding names! ðŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 191, 'prompt_tokens': 1736, 'total_tokens': 1927, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1664}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-Caezgvv20wT02ObAfOjQ4gsRYu9iz', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--9511b900-67b9-45de-b56a-29e84f6ee885-0', usage_metadata={'input_tokens': 1736, 'output_tokens': 191, 'total_tokens': 1927, 'input_token_details': {'audio': 0, 'cache_read': 1664}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream({\"messages\":\"yess\"},config=config,stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ac3f8",
   "metadata": {},
   "source": [
    "# HITL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24e1b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='I need some expert guidance and assistance in building an AI agent. Could you please assist me?', additional_kwargs={}, response_metadata={}, id='feb2303c-4a05-4001-b6e7-09727fafa8a2')]\n",
      "[HumanMessage(content='I need some expert guidance and assistance in building an AI agent. Could you please assist me?', additional_kwargs={}, response_metadata={}, id='feb2303c-4a05-4001-b6e7-09727fafa8a2'),\n",
      " AIMessage(content=\"Of course! I'd be happy to help you build an AI agent. To get started, could you share more details about your project? Here are some questions to guide us:\\n\\n1. **Purpose of the AI Agent**:\\n   - What is the primary function of your AI agent? (e.g., customer support, recommendation system, virtual assistant, data analysis, etc.)\\n\\n2. **Domain**:\\n   - Is your AI agent tailored to a specific industry or domain? (e.g., healthcare, e-commerce, education)\\n\\n3. **Core Features**:\\n   - What tasks do you want your AI agent to perform? (e.g., language understanding, decision-making, image recognition)\\n\\n4. **Input/Output**:\\n   - How will users interact with the AI agent? (e.g., text, voice, images, APIs)\\n   - What kind of responses will the agent provide?\\n\\n5. **Technology Stack**:\\n   - Are there any specific frameworks or tools you want to use? (e.g., Python, TensorFlow, OpenAI GPT, etc.)\\n   - Do you need recommendations for tools and libraries?\\n\\n6. **Deployment**:\\n   - Where will your AI agent run? (e.g., web-based, mobile app, desktop application, cloud service)\\n\\n7. **Challenges**:\\n   - Are there any specific challenges or constraints youâ€™re facing? (e.g., budget, lack of data, scalability)\\n\\nOnce you share more details, I can provide steps, resources, and recommendations tailored to your project!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 312, 'prompt_tokens': 1308, 'total_tokens': 1620, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-Caf7vpLT5zgJTSWEsgbDxDfg43Y4n', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--e7e6a19e-335b-4c99-bd83-5052cabc572f-0', usage_metadata={'input_tokens': 1308, 'output_tokens': 312, 'total_tokens': 1620, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import HumanMessage, BaseMessage\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import interrupt, Command\n",
    "from langchain_core.tools import tool\n",
    "import pprint\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List, add_messages]\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    # Pause here; the return value will be provided via graph.resume(...)\n",
    "    return interrupt({\"query\": query})\n",
    "\n",
    "tavily = TavilySearch(max_results=2)\n",
    "tools = [tavily, human_assistance]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def tool_calling_llm(state: GraphState) -> GraphState:\n",
    "    msg = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\":  [msg]}\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\")\n",
    "builder.add_edge(\"tools\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "user_ip = \"I need some expert guidance and assistance in building an AI agent. Could you please assist me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "stream = graph.stream(\n",
    "    {\"messages\": user_ip},\n",
    "    config=config,\n",
    "    stream_mode=\"values\",\n",
    "    interrupt_before=[\"tools\"],\n",
    ")\n",
    "\n",
    "# for ev in stream:\n",
    "#     if \"__interrupt__\" in ev:\n",
    "#         # youâ€™d collect real input here; using a stub string for demo\n",
    "#         human_help = \"Start by defining the agent's goal, tools, memory, and routing.\"\n",
    "#         graph.resume(Command(resume=human_help), config=config, stream_mode=\"values\")\n",
    "#     else:\n",
    "#         for m in ev[\"messages\"]:\n",
    "#             if isinstance(m, BaseMessage):\n",
    "#                 m.pretty_print()\n",
    "#             else:\n",
    "#                 print(m)\n",
    "\n",
    "for ev in stream:\n",
    "    if \"messages\" in ev:\n",
    "        # youâ€™d collect real input here; using a stub string for demo\n",
    "        human_help = \"Start by defining the agent's goal, tools, memory, and routing.\"\n",
    "        graph.invoke(Command(resume=human_help), config=config, stream_mode=\"values\")\n",
    "        pprint.pprint(ev[\"messages\"])\n",
    "    else:\n",
    "        for m in ev[\"messages\"]:\n",
    "            if isinstance(m, BaseMessage):\n",
    "                m.pretty_print()\n",
    "            else:\n",
    "                print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56693a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
